{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PyYphphmQh5a"
   },
   "source": [
    "# K vecinos más cercanos (K Nearest Neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5VZktJaNQh7i"
   },
   "source": [
    "En este notebook estudiaremos cómo utilizar el clasificador k-NN de scikit-learn y distintas formas de medir su funcionamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sldAjGERQh8-"
   },
   "source": [
    "## Conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XDEvmjG7Qh-D"
   },
   "source": [
    "Usaremos un conjunto de datos sobre cáncer de mama en el que se usan 30 variables, extraídas a partir de imágenes, para tratar de predecir si la paciente tiene o no la enfermedad.\n",
    "\n",
    "https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HT3WZqc8Qh_c",
    "outputId": "a64abdae-07d7-4bc0-fc62-bcda9692ecbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names of the features: ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "Names of classes: ['malignant' 'benign']\n",
      "Number of instances and features: (569, 30)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "breast = load_breast_cancer()\n",
    "\n",
    "print('Names of the features:', breast['feature_names'])\n",
    "print('Names of classes:', breast['target_names'])\n",
    "print('Number of instances and features:', breast['data'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yh7vTmS9QiDv",
    "outputId": "c146f8c1-cf69-4f03-d8c4-6a5a1a7c21fa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.990</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.71190</td>\n",
       "      <td>0.26540</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.570</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.24160</td>\n",
       "      <td>0.18600</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.690</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.45040</td>\n",
       "      <td>0.24300</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.420</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.68690</td>\n",
       "      <td>0.25750</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.290</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.40000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.450</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>0.2087</td>\n",
       "      <td>0.07613</td>\n",
       "      <td>...</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.53550</td>\n",
       "      <td>0.17410</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18.250</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>0.05742</td>\n",
       "      <td>...</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.37840</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.710</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>0.07451</td>\n",
       "      <td>...</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.26780</td>\n",
       "      <td>0.15560</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13.000</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.07389</td>\n",
       "      <td>...</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.53900</td>\n",
       "      <td>0.20600</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12.460</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.08243</td>\n",
       "      <td>...</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.10500</td>\n",
       "      <td>0.22100</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16.020</td>\n",
       "      <td>23.24</td>\n",
       "      <td>102.70</td>\n",
       "      <td>797.8</td>\n",
       "      <td>0.08206</td>\n",
       "      <td>0.06669</td>\n",
       "      <td>0.03299</td>\n",
       "      <td>0.03323</td>\n",
       "      <td>0.1528</td>\n",
       "      <td>0.05697</td>\n",
       "      <td>...</td>\n",
       "      <td>33.88</td>\n",
       "      <td>123.80</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>0.1181</td>\n",
       "      <td>0.1551</td>\n",
       "      <td>0.14590</td>\n",
       "      <td>0.09975</td>\n",
       "      <td>0.2948</td>\n",
       "      <td>0.08452</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15.780</td>\n",
       "      <td>17.89</td>\n",
       "      <td>103.60</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.09710</td>\n",
       "      <td>0.12920</td>\n",
       "      <td>0.09954</td>\n",
       "      <td>0.06606</td>\n",
       "      <td>0.1842</td>\n",
       "      <td>0.06082</td>\n",
       "      <td>...</td>\n",
       "      <td>27.28</td>\n",
       "      <td>136.50</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>0.1396</td>\n",
       "      <td>0.5609</td>\n",
       "      <td>0.39650</td>\n",
       "      <td>0.18100</td>\n",
       "      <td>0.3792</td>\n",
       "      <td>0.10480</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>19.170</td>\n",
       "      <td>24.80</td>\n",
       "      <td>132.40</td>\n",
       "      <td>1123.0</td>\n",
       "      <td>0.09740</td>\n",
       "      <td>0.24580</td>\n",
       "      <td>0.20650</td>\n",
       "      <td>0.11180</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07800</td>\n",
       "      <td>...</td>\n",
       "      <td>29.94</td>\n",
       "      <td>151.70</td>\n",
       "      <td>1332.0</td>\n",
       "      <td>0.1037</td>\n",
       "      <td>0.3903</td>\n",
       "      <td>0.36390</td>\n",
       "      <td>0.17670</td>\n",
       "      <td>0.3176</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15.850</td>\n",
       "      <td>23.95</td>\n",
       "      <td>103.70</td>\n",
       "      <td>782.7</td>\n",
       "      <td>0.08401</td>\n",
       "      <td>0.10020</td>\n",
       "      <td>0.09938</td>\n",
       "      <td>0.05364</td>\n",
       "      <td>0.1847</td>\n",
       "      <td>0.05338</td>\n",
       "      <td>...</td>\n",
       "      <td>27.66</td>\n",
       "      <td>112.00</td>\n",
       "      <td>876.5</td>\n",
       "      <td>0.1131</td>\n",
       "      <td>0.1924</td>\n",
       "      <td>0.23220</td>\n",
       "      <td>0.11190</td>\n",
       "      <td>0.2809</td>\n",
       "      <td>0.06287</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13.730</td>\n",
       "      <td>22.61</td>\n",
       "      <td>93.60</td>\n",
       "      <td>578.3</td>\n",
       "      <td>0.11310</td>\n",
       "      <td>0.22930</td>\n",
       "      <td>0.21280</td>\n",
       "      <td>0.08025</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.07682</td>\n",
       "      <td>...</td>\n",
       "      <td>32.01</td>\n",
       "      <td>108.80</td>\n",
       "      <td>697.7</td>\n",
       "      <td>0.1651</td>\n",
       "      <td>0.7725</td>\n",
       "      <td>0.69430</td>\n",
       "      <td>0.22080</td>\n",
       "      <td>0.3596</td>\n",
       "      <td>0.14310</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14.540</td>\n",
       "      <td>27.54</td>\n",
       "      <td>96.73</td>\n",
       "      <td>658.8</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.15950</td>\n",
       "      <td>0.16390</td>\n",
       "      <td>0.07364</td>\n",
       "      <td>0.2303</td>\n",
       "      <td>0.07077</td>\n",
       "      <td>...</td>\n",
       "      <td>37.13</td>\n",
       "      <td>124.10</td>\n",
       "      <td>943.2</td>\n",
       "      <td>0.1678</td>\n",
       "      <td>0.6577</td>\n",
       "      <td>0.70260</td>\n",
       "      <td>0.17120</td>\n",
       "      <td>0.4218</td>\n",
       "      <td>0.13410</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14.680</td>\n",
       "      <td>20.13</td>\n",
       "      <td>94.74</td>\n",
       "      <td>684.5</td>\n",
       "      <td>0.09867</td>\n",
       "      <td>0.07200</td>\n",
       "      <td>0.07395</td>\n",
       "      <td>0.05259</td>\n",
       "      <td>0.1586</td>\n",
       "      <td>0.05922</td>\n",
       "      <td>...</td>\n",
       "      <td>30.88</td>\n",
       "      <td>123.40</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>0.1464</td>\n",
       "      <td>0.1871</td>\n",
       "      <td>0.29140</td>\n",
       "      <td>0.16090</td>\n",
       "      <td>0.3029</td>\n",
       "      <td>0.08216</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16.130</td>\n",
       "      <td>20.68</td>\n",
       "      <td>108.10</td>\n",
       "      <td>798.8</td>\n",
       "      <td>0.11700</td>\n",
       "      <td>0.20220</td>\n",
       "      <td>0.17220</td>\n",
       "      <td>0.10280</td>\n",
       "      <td>0.2164</td>\n",
       "      <td>0.07356</td>\n",
       "      <td>...</td>\n",
       "      <td>31.48</td>\n",
       "      <td>136.80</td>\n",
       "      <td>1315.0</td>\n",
       "      <td>0.1789</td>\n",
       "      <td>0.4233</td>\n",
       "      <td>0.47840</td>\n",
       "      <td>0.20730</td>\n",
       "      <td>0.3706</td>\n",
       "      <td>0.11420</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.810</td>\n",
       "      <td>22.15</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>0.09831</td>\n",
       "      <td>0.10270</td>\n",
       "      <td>0.14790</td>\n",
       "      <td>0.09498</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>0.05395</td>\n",
       "      <td>...</td>\n",
       "      <td>30.88</td>\n",
       "      <td>186.80</td>\n",
       "      <td>2398.0</td>\n",
       "      <td>0.1512</td>\n",
       "      <td>0.3150</td>\n",
       "      <td>0.53720</td>\n",
       "      <td>0.23880</td>\n",
       "      <td>0.2768</td>\n",
       "      <td>0.07615</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>13.540</td>\n",
       "      <td>14.36</td>\n",
       "      <td>87.46</td>\n",
       "      <td>566.3</td>\n",
       "      <td>0.09779</td>\n",
       "      <td>0.08129</td>\n",
       "      <td>0.06664</td>\n",
       "      <td>0.04781</td>\n",
       "      <td>0.1885</td>\n",
       "      <td>0.05766</td>\n",
       "      <td>...</td>\n",
       "      <td>19.26</td>\n",
       "      <td>99.70</td>\n",
       "      <td>711.2</td>\n",
       "      <td>0.1440</td>\n",
       "      <td>0.1773</td>\n",
       "      <td>0.23900</td>\n",
       "      <td>0.12880</td>\n",
       "      <td>0.2977</td>\n",
       "      <td>0.07259</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>13.080</td>\n",
       "      <td>15.71</td>\n",
       "      <td>85.63</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.10750</td>\n",
       "      <td>0.12700</td>\n",
       "      <td>0.04568</td>\n",
       "      <td>0.03110</td>\n",
       "      <td>0.1967</td>\n",
       "      <td>0.06811</td>\n",
       "      <td>...</td>\n",
       "      <td>20.49</td>\n",
       "      <td>96.09</td>\n",
       "      <td>630.5</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>0.2776</td>\n",
       "      <td>0.18900</td>\n",
       "      <td>0.07283</td>\n",
       "      <td>0.3184</td>\n",
       "      <td>0.08183</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9.504</td>\n",
       "      <td>12.44</td>\n",
       "      <td>60.34</td>\n",
       "      <td>273.9</td>\n",
       "      <td>0.10240</td>\n",
       "      <td>0.06492</td>\n",
       "      <td>0.02956</td>\n",
       "      <td>0.02076</td>\n",
       "      <td>0.1815</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>...</td>\n",
       "      <td>15.66</td>\n",
       "      <td>65.13</td>\n",
       "      <td>314.9</td>\n",
       "      <td>0.1324</td>\n",
       "      <td>0.1148</td>\n",
       "      <td>0.08867</td>\n",
       "      <td>0.06227</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>0.07773</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15.340</td>\n",
       "      <td>14.26</td>\n",
       "      <td>102.50</td>\n",
       "      <td>704.4</td>\n",
       "      <td>0.10730</td>\n",
       "      <td>0.21350</td>\n",
       "      <td>0.20770</td>\n",
       "      <td>0.09756</td>\n",
       "      <td>0.2521</td>\n",
       "      <td>0.07032</td>\n",
       "      <td>...</td>\n",
       "      <td>19.08</td>\n",
       "      <td>125.10</td>\n",
       "      <td>980.9</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>0.5954</td>\n",
       "      <td>0.63050</td>\n",
       "      <td>0.23930</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.09946</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>21.160</td>\n",
       "      <td>23.04</td>\n",
       "      <td>137.20</td>\n",
       "      <td>1404.0</td>\n",
       "      <td>0.09428</td>\n",
       "      <td>0.10220</td>\n",
       "      <td>0.10970</td>\n",
       "      <td>0.08632</td>\n",
       "      <td>0.1769</td>\n",
       "      <td>0.05278</td>\n",
       "      <td>...</td>\n",
       "      <td>35.59</td>\n",
       "      <td>188.00</td>\n",
       "      <td>2615.0</td>\n",
       "      <td>0.1401</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.31550</td>\n",
       "      <td>0.20090</td>\n",
       "      <td>0.2822</td>\n",
       "      <td>0.07526</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>16.650</td>\n",
       "      <td>21.38</td>\n",
       "      <td>110.00</td>\n",
       "      <td>904.6</td>\n",
       "      <td>0.11210</td>\n",
       "      <td>0.14570</td>\n",
       "      <td>0.15250</td>\n",
       "      <td>0.09170</td>\n",
       "      <td>0.1995</td>\n",
       "      <td>0.06330</td>\n",
       "      <td>...</td>\n",
       "      <td>31.56</td>\n",
       "      <td>177.00</td>\n",
       "      <td>2215.0</td>\n",
       "      <td>0.1805</td>\n",
       "      <td>0.3578</td>\n",
       "      <td>0.46950</td>\n",
       "      <td>0.20950</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.09564</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.990         10.38          122.80     1001.0          0.11840   \n",
       "1        20.570         17.77          132.90     1326.0          0.08474   \n",
       "2        19.690         21.25          130.00     1203.0          0.10960   \n",
       "3        11.420         20.38           77.58      386.1          0.14250   \n",
       "4        20.290         14.34          135.10     1297.0          0.10030   \n",
       "5        12.450         15.70           82.57      477.1          0.12780   \n",
       "6        18.250         19.98          119.60     1040.0          0.09463   \n",
       "7        13.710         20.83           90.20      577.9          0.11890   \n",
       "8        13.000         21.82           87.50      519.8          0.12730   \n",
       "9        12.460         24.04           83.97      475.9          0.11860   \n",
       "10       16.020         23.24          102.70      797.8          0.08206   \n",
       "11       15.780         17.89          103.60      781.0          0.09710   \n",
       "12       19.170         24.80          132.40     1123.0          0.09740   \n",
       "13       15.850         23.95          103.70      782.7          0.08401   \n",
       "14       13.730         22.61           93.60      578.3          0.11310   \n",
       "15       14.540         27.54           96.73      658.8          0.11390   \n",
       "16       14.680         20.13           94.74      684.5          0.09867   \n",
       "17       16.130         20.68          108.10      798.8          0.11700   \n",
       "18       19.810         22.15          130.00     1260.0          0.09831   \n",
       "19       13.540         14.36           87.46      566.3          0.09779   \n",
       "20       13.080         15.71           85.63      520.0          0.10750   \n",
       "21        9.504         12.44           60.34      273.9          0.10240   \n",
       "22       15.340         14.26          102.50      704.4          0.10730   \n",
       "23       21.160         23.04          137.20     1404.0          0.09428   \n",
       "24       16.650         21.38          110.00      904.6          0.11210   \n",
       "\n",
       "    mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0            0.27760         0.30010              0.14710         0.2419   \n",
       "1            0.07864         0.08690              0.07017         0.1812   \n",
       "2            0.15990         0.19740              0.12790         0.2069   \n",
       "3            0.28390         0.24140              0.10520         0.2597   \n",
       "4            0.13280         0.19800              0.10430         0.1809   \n",
       "5            0.17000         0.15780              0.08089         0.2087   \n",
       "6            0.10900         0.11270              0.07400         0.1794   \n",
       "7            0.16450         0.09366              0.05985         0.2196   \n",
       "8            0.19320         0.18590              0.09353         0.2350   \n",
       "9            0.23960         0.22730              0.08543         0.2030   \n",
       "10           0.06669         0.03299              0.03323         0.1528   \n",
       "11           0.12920         0.09954              0.06606         0.1842   \n",
       "12           0.24580         0.20650              0.11180         0.2397   \n",
       "13           0.10020         0.09938              0.05364         0.1847   \n",
       "14           0.22930         0.21280              0.08025         0.2069   \n",
       "15           0.15950         0.16390              0.07364         0.2303   \n",
       "16           0.07200         0.07395              0.05259         0.1586   \n",
       "17           0.20220         0.17220              0.10280         0.2164   \n",
       "18           0.10270         0.14790              0.09498         0.1582   \n",
       "19           0.08129         0.06664              0.04781         0.1885   \n",
       "20           0.12700         0.04568              0.03110         0.1967   \n",
       "21           0.06492         0.02956              0.02076         0.1815   \n",
       "22           0.21350         0.20770              0.09756         0.2521   \n",
       "23           0.10220         0.10970              0.08632         0.1769   \n",
       "24           0.14570         0.15250              0.09170         0.1995   \n",
       "\n",
       "    mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                  0.07871  ...          17.33           184.60      2019.0   \n",
       "1                  0.05667  ...          23.41           158.80      1956.0   \n",
       "2                  0.05999  ...          25.53           152.50      1709.0   \n",
       "3                  0.09744  ...          26.50            98.87       567.7   \n",
       "4                  0.05883  ...          16.67           152.20      1575.0   \n",
       "5                  0.07613  ...          23.75           103.40       741.6   \n",
       "6                  0.05742  ...          27.66           153.20      1606.0   \n",
       "7                  0.07451  ...          28.14           110.60       897.0   \n",
       "8                  0.07389  ...          30.73           106.20       739.3   \n",
       "9                  0.08243  ...          40.68            97.65       711.4   \n",
       "10                 0.05697  ...          33.88           123.80      1150.0   \n",
       "11                 0.06082  ...          27.28           136.50      1299.0   \n",
       "12                 0.07800  ...          29.94           151.70      1332.0   \n",
       "13                 0.05338  ...          27.66           112.00       876.5   \n",
       "14                 0.07682  ...          32.01           108.80       697.7   \n",
       "15                 0.07077  ...          37.13           124.10       943.2   \n",
       "16                 0.05922  ...          30.88           123.40      1138.0   \n",
       "17                 0.07356  ...          31.48           136.80      1315.0   \n",
       "18                 0.05395  ...          30.88           186.80      2398.0   \n",
       "19                 0.05766  ...          19.26            99.70       711.2   \n",
       "20                 0.06811  ...          20.49            96.09       630.5   \n",
       "21                 0.06905  ...          15.66            65.13       314.9   \n",
       "22                 0.07032  ...          19.08           125.10       980.9   \n",
       "23                 0.05278  ...          35.59           188.00      2615.0   \n",
       "24                 0.06330  ...          31.56           177.00      2215.0   \n",
       "\n",
       "    worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.1622             0.6656          0.71190   \n",
       "1             0.1238             0.1866          0.24160   \n",
       "2             0.1444             0.4245          0.45040   \n",
       "3             0.2098             0.8663          0.68690   \n",
       "4             0.1374             0.2050          0.40000   \n",
       "5             0.1791             0.5249          0.53550   \n",
       "6             0.1442             0.2576          0.37840   \n",
       "7             0.1654             0.3682          0.26780   \n",
       "8             0.1703             0.5401          0.53900   \n",
       "9             0.1853             1.0580          1.10500   \n",
       "10            0.1181             0.1551          0.14590   \n",
       "11            0.1396             0.5609          0.39650   \n",
       "12            0.1037             0.3903          0.36390   \n",
       "13            0.1131             0.1924          0.23220   \n",
       "14            0.1651             0.7725          0.69430   \n",
       "15            0.1678             0.6577          0.70260   \n",
       "16            0.1464             0.1871          0.29140   \n",
       "17            0.1789             0.4233          0.47840   \n",
       "18            0.1512             0.3150          0.53720   \n",
       "19            0.1440             0.1773          0.23900   \n",
       "20            0.1312             0.2776          0.18900   \n",
       "21            0.1324             0.1148          0.08867   \n",
       "22            0.1390             0.5954          0.63050   \n",
       "23            0.1401             0.2600          0.31550   \n",
       "24            0.1805             0.3578          0.46950   \n",
       "\n",
       "    worst concave points  worst symmetry  worst fractal dimension     result  \n",
       "0                0.26540          0.4601                  0.11890  malignant  \n",
       "1                0.18600          0.2750                  0.08902  malignant  \n",
       "2                0.24300          0.3613                  0.08758  malignant  \n",
       "3                0.25750          0.6638                  0.17300  malignant  \n",
       "4                0.16250          0.2364                  0.07678  malignant  \n",
       "5                0.17410          0.3985                  0.12440  malignant  \n",
       "6                0.19320          0.3063                  0.08368  malignant  \n",
       "7                0.15560          0.3196                  0.11510  malignant  \n",
       "8                0.20600          0.4378                  0.10720  malignant  \n",
       "9                0.22100          0.4366                  0.20750  malignant  \n",
       "10               0.09975          0.2948                  0.08452  malignant  \n",
       "11               0.18100          0.3792                  0.10480  malignant  \n",
       "12               0.17670          0.3176                  0.10230  malignant  \n",
       "13               0.11190          0.2809                  0.06287  malignant  \n",
       "14               0.22080          0.3596                  0.14310  malignant  \n",
       "15               0.17120          0.4218                  0.13410  malignant  \n",
       "16               0.16090          0.3029                  0.08216  malignant  \n",
       "17               0.20730          0.3706                  0.11420  malignant  \n",
       "18               0.23880          0.2768                  0.07615  malignant  \n",
       "19               0.12880          0.2977                  0.07259     benign  \n",
       "20               0.07283          0.3184                  0.08183     benign  \n",
       "21               0.06227          0.2450                  0.07773     benign  \n",
       "22               0.23930          0.4667                  0.09946  malignant  \n",
       "23               0.20090          0.2822                  0.07526  malignant  \n",
       "24               0.20950          0.3613                  0.09564  malignant  \n",
       "\n",
       "[25 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Crear la tabla y añadir una columna con la clase que se trata de predecir\n",
    "df = pd.DataFrame(data=breast['data'], columns=breast['feature_names']) \n",
    "df['result'] = breast['target']\n",
    "df['result'] = df['result'].map({0: 'malignant', 1: 'benign'})\n",
    "\n",
    "df.head(25) # Sólo mostramos las primeras filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "benign       357\n",
       "malignant    212\n",
       "Name: result, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Número de ejemplos en cada clase\n",
    "df['result'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SdoSrlk-QiHC",
    "outputId": "73c127ce-50ce-4734-8a1d-3663273c4b6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "benign       62.741652\n",
       "malignant    37.258348\n",
       "Name: result, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Frecuencia de las clases\n",
    "df['result'].value_counts() / df['result'].count() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ksAXBNlQiKI"
   },
   "source": [
    "En este caso la clase \"benigna\" es más frecuente que la benigna (aprox. 2/3 frente a 1/3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MgcDVji4QiK0"
   },
   "source": [
    "## Normalización de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CsxJMhnaQiLh"
   },
   "source": [
    "Las variables de este conjunto de datos son numéricas pero de una escala muy diferente por lo que para usar determinadas técnicas (como las basadas en distancia, como el k-NN, y en regresión de variables, como las redes neuronales) suele ser conveniente escalar los datos. \n",
    "\n",
    "__IMPORTANTE: Recuerda escalar los datos__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9GhKqPhIQiMn",
    "outputId": "c063dc0c-7afb-48dc-a0b6-c667c8e97b59"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean radius  mean texture  mean perimeter    mean area  \\\n",
       "count   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     14.127292     19.289649       91.969033   654.889104   \n",
       "std       3.524049      4.301036       24.298981   351.914129   \n",
       "min       6.981000      9.710000       43.790000   143.500000   \n",
       "25%      11.700000     16.170000       75.170000   420.300000   \n",
       "50%      13.370000     18.840000       86.240000   551.100000   \n",
       "75%      15.780000     21.800000      104.100000   782.700000   \n",
       "max      28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       mean symmetry  mean fractal dimension  ...  worst radius  \\\n",
       "count     569.000000              569.000000  ...    569.000000   \n",
       "mean        0.181162                0.062798  ...     16.269190   \n",
       "std         0.027414                0.007060  ...      4.833242   \n",
       "min         0.106000                0.049960  ...      7.930000   \n",
       "25%         0.161900                0.057700  ...     13.010000   \n",
       "50%         0.179200                0.061540  ...     14.970000   \n",
       "75%         0.195700                0.066120  ...     18.790000   \n",
       "max         0.304000                0.097440  ...     36.040000   \n",
       "\n",
       "       worst texture  worst perimeter   worst area  worst smoothness  \\\n",
       "count     569.000000       569.000000   569.000000        569.000000   \n",
       "mean       25.677223       107.261213   880.583128          0.132369   \n",
       "std         6.146258        33.602542   569.356993          0.022832   \n",
       "min        12.020000        50.410000   185.200000          0.071170   \n",
       "25%        21.080000        84.110000   515.300000          0.116600   \n",
       "50%        25.410000        97.660000   686.500000          0.131300   \n",
       "75%        29.720000       125.400000  1084.000000          0.146000   \n",
       "max        49.540000       251.200000  4254.000000          0.222600   \n",
       "\n",
       "       worst compactness  worst concavity  worst concave points  \\\n",
       "count         569.000000       569.000000            569.000000   \n",
       "mean            0.254265         0.272188              0.114606   \n",
       "std             0.157336         0.208624              0.065732   \n",
       "min             0.027290         0.000000              0.000000   \n",
       "25%             0.147200         0.114500              0.064930   \n",
       "50%             0.211900         0.226700              0.099930   \n",
       "75%             0.339100         0.382900              0.161400   \n",
       "max             1.058000         1.252000              0.291000   \n",
       "\n",
       "       worst symmetry  worst fractal dimension  \n",
       "count      569.000000               569.000000  \n",
       "mean         0.290076                 0.083946  \n",
       "std          0.061867                 0.018061  \n",
       "min          0.156500                 0.055040  \n",
       "25%          0.250400                 0.071460  \n",
       "50%          0.282200                 0.080040  \n",
       "75%          0.317900                 0.092080  \n",
       "max          0.663800                 0.207500  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nqESy1L9QiQG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Normalizamos los datos escalándolos al intervalo [0,1]\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(breast['data'])\n",
    "breast['data_scaled'] = scaler.transform(breast.data) # Lo almacenamos en el dataset original\n",
    "\n",
    "breast['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mgyUOrYyQiSQ",
    "outputId": "5c158e3c-5355-4b1a-c28e-67128addcce4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.338222</td>\n",
       "      <td>0.323965</td>\n",
       "      <td>0.332935</td>\n",
       "      <td>0.216920</td>\n",
       "      <td>0.394785</td>\n",
       "      <td>0.260601</td>\n",
       "      <td>0.208058</td>\n",
       "      <td>0.243137</td>\n",
       "      <td>0.379605</td>\n",
       "      <td>0.270379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296663</td>\n",
       "      <td>0.363998</td>\n",
       "      <td>0.283138</td>\n",
       "      <td>0.170906</td>\n",
       "      <td>0.404138</td>\n",
       "      <td>0.220212</td>\n",
       "      <td>0.217403</td>\n",
       "      <td>0.393836</td>\n",
       "      <td>0.263307</td>\n",
       "      <td>0.189596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.166787</td>\n",
       "      <td>0.145453</td>\n",
       "      <td>0.167915</td>\n",
       "      <td>0.149274</td>\n",
       "      <td>0.126967</td>\n",
       "      <td>0.161992</td>\n",
       "      <td>0.186785</td>\n",
       "      <td>0.192857</td>\n",
       "      <td>0.138456</td>\n",
       "      <td>0.148702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171940</td>\n",
       "      <td>0.163813</td>\n",
       "      <td>0.167352</td>\n",
       "      <td>0.139932</td>\n",
       "      <td>0.150779</td>\n",
       "      <td>0.152649</td>\n",
       "      <td>0.166633</td>\n",
       "      <td>0.225884</td>\n",
       "      <td>0.121954</td>\n",
       "      <td>0.118466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.223342</td>\n",
       "      <td>0.218465</td>\n",
       "      <td>0.216847</td>\n",
       "      <td>0.117413</td>\n",
       "      <td>0.304595</td>\n",
       "      <td>0.139685</td>\n",
       "      <td>0.069260</td>\n",
       "      <td>0.100944</td>\n",
       "      <td>0.282323</td>\n",
       "      <td>0.163016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180719</td>\n",
       "      <td>0.241471</td>\n",
       "      <td>0.167837</td>\n",
       "      <td>0.081130</td>\n",
       "      <td>0.300007</td>\n",
       "      <td>0.116337</td>\n",
       "      <td>0.091454</td>\n",
       "      <td>0.223127</td>\n",
       "      <td>0.185098</td>\n",
       "      <td>0.107700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.302381</td>\n",
       "      <td>0.308759</td>\n",
       "      <td>0.293345</td>\n",
       "      <td>0.172895</td>\n",
       "      <td>0.390358</td>\n",
       "      <td>0.224679</td>\n",
       "      <td>0.144189</td>\n",
       "      <td>0.166501</td>\n",
       "      <td>0.369697</td>\n",
       "      <td>0.243892</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250445</td>\n",
       "      <td>0.356876</td>\n",
       "      <td>0.235320</td>\n",
       "      <td>0.123206</td>\n",
       "      <td>0.397081</td>\n",
       "      <td>0.179110</td>\n",
       "      <td>0.181070</td>\n",
       "      <td>0.343402</td>\n",
       "      <td>0.247782</td>\n",
       "      <td>0.163977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.416442</td>\n",
       "      <td>0.408860</td>\n",
       "      <td>0.416765</td>\n",
       "      <td>0.271135</td>\n",
       "      <td>0.475490</td>\n",
       "      <td>0.340531</td>\n",
       "      <td>0.306232</td>\n",
       "      <td>0.367793</td>\n",
       "      <td>0.453030</td>\n",
       "      <td>0.340354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386339</td>\n",
       "      <td>0.471748</td>\n",
       "      <td>0.373475</td>\n",
       "      <td>0.220901</td>\n",
       "      <td>0.494156</td>\n",
       "      <td>0.302520</td>\n",
       "      <td>0.305831</td>\n",
       "      <td>0.554639</td>\n",
       "      <td>0.318155</td>\n",
       "      <td>0.242949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean radius  mean texture  mean perimeter   mean area  mean smoothness  \\\n",
       "count   569.000000    569.000000      569.000000  569.000000       569.000000   \n",
       "mean      0.338222      0.323965        0.332935    0.216920         0.394785   \n",
       "std       0.166787      0.145453        0.167915    0.149274         0.126967   \n",
       "min       0.000000      0.000000        0.000000    0.000000         0.000000   \n",
       "25%       0.223342      0.218465        0.216847    0.117413         0.304595   \n",
       "50%       0.302381      0.308759        0.293345    0.172895         0.390358   \n",
       "75%       0.416442      0.408860        0.416765    0.271135         0.475490   \n",
       "max       1.000000      1.000000        1.000000    1.000000         1.000000   \n",
       "\n",
       "       mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "count        569.000000      569.000000           569.000000     569.000000   \n",
       "mean           0.260601        0.208058             0.243137       0.379605   \n",
       "std            0.161992        0.186785             0.192857       0.138456   \n",
       "min            0.000000        0.000000             0.000000       0.000000   \n",
       "25%            0.139685        0.069260             0.100944       0.282323   \n",
       "50%            0.224679        0.144189             0.166501       0.369697   \n",
       "75%            0.340531        0.306232             0.367793       0.453030   \n",
       "max            1.000000        1.000000             1.000000       1.000000   \n",
       "\n",
       "       mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "count              569.000000  ...    569.000000     569.000000   \n",
       "mean                 0.270379  ...      0.296663       0.363998   \n",
       "std                  0.148702  ...      0.171940       0.163813   \n",
       "min                  0.000000  ...      0.000000       0.000000   \n",
       "25%                  0.163016  ...      0.180719       0.241471   \n",
       "50%                  0.243892  ...      0.250445       0.356876   \n",
       "75%                  0.340354  ...      0.386339       0.471748   \n",
       "max                  1.000000  ...      1.000000       1.000000   \n",
       "\n",
       "       worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "count       569.000000  569.000000        569.000000         569.000000   \n",
       "mean          0.283138    0.170906          0.404138           0.220212   \n",
       "std           0.167352    0.139932          0.150779           0.152649   \n",
       "min           0.000000    0.000000          0.000000           0.000000   \n",
       "25%           0.167837    0.081130          0.300007           0.116337   \n",
       "50%           0.235320    0.123206          0.397081           0.179110   \n",
       "75%           0.373475    0.220901          0.494156           0.302520   \n",
       "max           1.000000    1.000000          1.000000           1.000000   \n",
       "\n",
       "       worst concavity  worst concave points  worst symmetry  \\\n",
       "count       569.000000            569.000000      569.000000   \n",
       "mean          0.217403              0.393836        0.263307   \n",
       "std           0.166633              0.225884        0.121954   \n",
       "min           0.000000              0.000000        0.000000   \n",
       "25%           0.091454              0.223127        0.185098   \n",
       "50%           0.181070              0.343402        0.247782   \n",
       "75%           0.305831              0.554639        0.318155   \n",
       "max           1.000000              1.000000        1.000000   \n",
       "\n",
       "       worst fractal dimension  \n",
       "count               569.000000  \n",
       "mean                  0.189596  \n",
       "std                   0.118466  \n",
       "min                   0.000000  \n",
       "25%                   0.107700  \n",
       "50%                   0.163977  \n",
       "75%                   0.242949  \n",
       "max                   1.000000  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos un nuevo dataframe con los datos escalados\n",
    "df_scaled = pd.DataFrame(data=breast['data_scaled'], columns=breast['feature_names'])\n",
    "df_scaled['result'] = breast['target']\n",
    "df_scaled['result'] = df_scaled['result'].map({0: 'malignant', 1: 'benign'})\n",
    "df_scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean radius</th>\n",
       "      <td>0.521037</td>\n",
       "      <td>0.643144</td>\n",
       "      <td>0.601496</td>\n",
       "      <td>0.21009</td>\n",
       "      <td>0.629893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean texture</th>\n",
       "      <td>0.0226581</td>\n",
       "      <td>0.272574</td>\n",
       "      <td>0.39026</td>\n",
       "      <td>0.360839</td>\n",
       "      <td>0.156578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean perimeter</th>\n",
       "      <td>0.545989</td>\n",
       "      <td>0.615783</td>\n",
       "      <td>0.595743</td>\n",
       "      <td>0.233501</td>\n",
       "      <td>0.630986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean area</th>\n",
       "      <td>0.363733</td>\n",
       "      <td>0.501591</td>\n",
       "      <td>0.449417</td>\n",
       "      <td>0.102906</td>\n",
       "      <td>0.48929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean smoothness</th>\n",
       "      <td>0.593753</td>\n",
       "      <td>0.28988</td>\n",
       "      <td>0.514309</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.430351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean compactness</th>\n",
       "      <td>0.792037</td>\n",
       "      <td>0.181768</td>\n",
       "      <td>0.431017</td>\n",
       "      <td>0.811361</td>\n",
       "      <td>0.347893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean concavity</th>\n",
       "      <td>0.70314</td>\n",
       "      <td>0.203608</td>\n",
       "      <td>0.462512</td>\n",
       "      <td>0.565604</td>\n",
       "      <td>0.463918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean concave points</th>\n",
       "      <td>0.731113</td>\n",
       "      <td>0.348757</td>\n",
       "      <td>0.635686</td>\n",
       "      <td>0.522863</td>\n",
       "      <td>0.51839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean symmetry</th>\n",
       "      <td>0.686364</td>\n",
       "      <td>0.379798</td>\n",
       "      <td>0.509596</td>\n",
       "      <td>0.776263</td>\n",
       "      <td>0.378283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <td>0.605518</td>\n",
       "      <td>0.141323</td>\n",
       "      <td>0.211247</td>\n",
       "      <td>1</td>\n",
       "      <td>0.186816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius error</th>\n",
       "      <td>0.356147</td>\n",
       "      <td>0.156437</td>\n",
       "      <td>0.229622</td>\n",
       "      <td>0.139091</td>\n",
       "      <td>0.233822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture error</th>\n",
       "      <td>0.120469</td>\n",
       "      <td>0.0825893</td>\n",
       "      <td>0.0943025</td>\n",
       "      <td>0.175875</td>\n",
       "      <td>0.0930649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter error</th>\n",
       "      <td>0.369034</td>\n",
       "      <td>0.12444</td>\n",
       "      <td>0.18037</td>\n",
       "      <td>0.126655</td>\n",
       "      <td>0.220563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area error</th>\n",
       "      <td>0.273811</td>\n",
       "      <td>0.12566</td>\n",
       "      <td>0.162922</td>\n",
       "      <td>0.0381548</td>\n",
       "      <td>0.163688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness error</th>\n",
       "      <td>0.159296</td>\n",
       "      <td>0.119387</td>\n",
       "      <td>0.150831</td>\n",
       "      <td>0.251453</td>\n",
       "      <td>0.332359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness error</th>\n",
       "      <td>0.351398</td>\n",
       "      <td>0.081323</td>\n",
       "      <td>0.283955</td>\n",
       "      <td>0.543215</td>\n",
       "      <td>0.167918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity error</th>\n",
       "      <td>0.135682</td>\n",
       "      <td>0.0469697</td>\n",
       "      <td>0.0967677</td>\n",
       "      <td>0.142955</td>\n",
       "      <td>0.143636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points error</th>\n",
       "      <td>0.300625</td>\n",
       "      <td>0.253836</td>\n",
       "      <td>0.389847</td>\n",
       "      <td>0.353665</td>\n",
       "      <td>0.357075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry error</th>\n",
       "      <td>0.311645</td>\n",
       "      <td>0.0845388</td>\n",
       "      <td>0.20569</td>\n",
       "      <td>0.728148</td>\n",
       "      <td>0.136179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal dimension error</th>\n",
       "      <td>0.183042</td>\n",
       "      <td>0.0911101</td>\n",
       "      <td>0.127006</td>\n",
       "      <td>0.287205</td>\n",
       "      <td>0.1458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst radius</th>\n",
       "      <td>0.620776</td>\n",
       "      <td>0.606901</td>\n",
       "      <td>0.556386</td>\n",
       "      <td>0.24831</td>\n",
       "      <td>0.519744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst texture</th>\n",
       "      <td>0.141525</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.360075</td>\n",
       "      <td>0.385928</td>\n",
       "      <td>0.123934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst perimeter</th>\n",
       "      <td>0.66831</td>\n",
       "      <td>0.539818</td>\n",
       "      <td>0.508442</td>\n",
       "      <td>0.241347</td>\n",
       "      <td>0.506948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst area</th>\n",
       "      <td>0.450698</td>\n",
       "      <td>0.435214</td>\n",
       "      <td>0.374508</td>\n",
       "      <td>0.0940081</td>\n",
       "      <td>0.341575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst smoothness</th>\n",
       "      <td>0.601136</td>\n",
       "      <td>0.347553</td>\n",
       "      <td>0.48359</td>\n",
       "      <td>0.915472</td>\n",
       "      <td>0.437364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst compactness</th>\n",
       "      <td>0.619292</td>\n",
       "      <td>0.154563</td>\n",
       "      <td>0.385375</td>\n",
       "      <td>0.814012</td>\n",
       "      <td>0.172415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst concavity</th>\n",
       "      <td>0.56861</td>\n",
       "      <td>0.192971</td>\n",
       "      <td>0.359744</td>\n",
       "      <td>0.548642</td>\n",
       "      <td>0.319489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst concave points</th>\n",
       "      <td>0.912027</td>\n",
       "      <td>0.639175</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.88488</td>\n",
       "      <td>0.558419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst symmetry</th>\n",
       "      <td>0.598462</td>\n",
       "      <td>0.23359</td>\n",
       "      <td>0.403706</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <td>0.418864</td>\n",
       "      <td>0.222878</td>\n",
       "      <td>0.213433</td>\n",
       "      <td>0.773711</td>\n",
       "      <td>0.142595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>result</th>\n",
       "      <td>malignant</td>\n",
       "      <td>malignant</td>\n",
       "      <td>malignant</td>\n",
       "      <td>malignant</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0          1          2          3          4\n",
       "mean radius               0.521037   0.643144   0.601496    0.21009   0.629893\n",
       "mean texture             0.0226581   0.272574    0.39026   0.360839   0.156578\n",
       "mean perimeter            0.545989   0.615783   0.595743   0.233501   0.630986\n",
       "mean area                 0.363733   0.501591   0.449417   0.102906    0.48929\n",
       "mean smoothness           0.593753    0.28988   0.514309   0.811321   0.430351\n",
       "mean compactness          0.792037   0.181768   0.431017   0.811361   0.347893\n",
       "mean concavity             0.70314   0.203608   0.462512   0.565604   0.463918\n",
       "mean concave points       0.731113   0.348757   0.635686   0.522863    0.51839\n",
       "mean symmetry             0.686364   0.379798   0.509596   0.776263   0.378283\n",
       "mean fractal dimension    0.605518   0.141323   0.211247          1   0.186816\n",
       "radius error              0.356147   0.156437   0.229622   0.139091   0.233822\n",
       "texture error             0.120469  0.0825893  0.0943025   0.175875  0.0930649\n",
       "perimeter error           0.369034    0.12444    0.18037   0.126655   0.220563\n",
       "area error                0.273811    0.12566   0.162922  0.0381548   0.163688\n",
       "smoothness error          0.159296   0.119387   0.150831   0.251453   0.332359\n",
       "compactness error         0.351398   0.081323   0.283955   0.543215   0.167918\n",
       "concavity error           0.135682  0.0469697  0.0967677   0.142955   0.143636\n",
       "concave points error      0.300625   0.253836   0.389847   0.353665   0.357075\n",
       "symmetry error            0.311645  0.0845388    0.20569   0.728148   0.136179\n",
       "fractal dimension error   0.183042  0.0911101   0.127006   0.287205     0.1458\n",
       "worst radius              0.620776   0.606901   0.556386    0.24831   0.519744\n",
       "worst texture             0.141525   0.303571   0.360075   0.385928   0.123934\n",
       "worst perimeter            0.66831   0.539818   0.508442   0.241347   0.506948\n",
       "worst area                0.450698   0.435214   0.374508  0.0940081   0.341575\n",
       "worst smoothness          0.601136   0.347553    0.48359   0.915472   0.437364\n",
       "worst compactness         0.619292   0.154563   0.385375   0.814012   0.172415\n",
       "worst concavity            0.56861   0.192971   0.359744   0.548642   0.319489\n",
       "worst concave points      0.912027   0.639175   0.835052    0.88488   0.558419\n",
       "worst symmetry            0.598462    0.23359   0.403706          1     0.1575\n",
       "worst fractal dimension   0.418864   0.222878   0.213433   0.773711   0.142595\n",
       "result                   malignant  malignant  malignant  malignant  malignant"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled.head().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HqGvjg-fQiWe"
   },
   "source": [
    "## Conjuntos de entrenamiento y test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LWtaN11xQiW-"
   },
   "source": [
    "Podemos utilizar distintas técnicas para medir el funcionamiento de un clasificador (train/test split, leave one out, cross validation, ...). Una de las técnicas más habituales consiste en dividir el conjunto de datos en dos partes: entrenamiento y prueba. Entrenamos el clasificador con el conjunto de entrenamiento y probamos su funcionamiento con el conjunto de prueba. __Es muy importante que las métricas de clasificación se midan sobre un conjunto de datos distinto del que se usó para entrenar al clasificador__.\n",
    "\n",
    "Además, en este caso las clases no están balanceadas (2/3 y 1/3) por lo que debemos hacer una __partición estratificada__ que mantenga esa proporción en los dos conjuntos de datos.\n",
    "\n",
    "Finalmente, fíjate que __las clases de sklearn trabajan siempre con arrays de numpy y no con dataframes de Pandas__. Los datos del dataset original están en arrays así que podemos usarlos directamente. Si necesitáramos acceder al array que hay en un dataframe también podríamos hacerlo mediante el atributo _data_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q_0ZD15hQiXw",
    "outputId": "a373a220-1970-497e-9358-73fdeadc4fab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.9649122807017544)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Como la proporción de clases a predecir está desbalanceada (2/3 y 1/3) es importante\n",
    "# usar la versión estratificada que mantiene la proporción de elementos de cada clase \n",
    "# al hacer la partición\n",
    "# En este caso usamos el 80% de instancias como conjunto de entrenamiento y el 20% como\n",
    "# conjunto de prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(breast['data_scaled'], breast['target'], \n",
    "                                                    test_size=0.20, stratify=breast['target'],\n",
    "                                                    random_state=55)\n",
    "\n",
    "# Creamos el clasificador k-NN\n",
    "# Podemos fijar los pesos como 'uniform' o inv. proporcionales a la distancia 'distance'\n",
    "clf = KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
    "\n",
    "# Entrenar el clasificador\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Medir la tasa de aciertos o exactitud (accuracy) en los conjuntos de entrenamiento y test\n",
    "train_accuracy = clf.score(X_train, y_train)\n",
    "test_accuracy = clf.score(X_test, y_test)\n",
    "\n",
    "train_accuracy, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ib8tThr-Qiaw"
   },
   "source": [
    "El valor de accuracy para el conjunto de entrenamiento siempre es más alto que para el conjunto de test (¡al final y al cabo estamos prediciendo datos que se han usado para entrenar el modelo!). De hecho, en el caso de k-NN siempre será del 100% porque el algoritmo almacena todos los datos de entrenamiento. __Siempre debemos calcular las métricas sobre el conjunto de prueba__ si queremos obtener valores reales sobre el funcionamiento del clasificador. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q-WKWelOQib0"
   },
   "source": [
    "## Matriz de confusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RNqO3WjjQic-"
   },
   "source": [
    "La matriz de confusión nos permite ver el número de instancias real de cada clase y el número de instancias predichas por el clasificador. Permite comprobar fácilmente las clases que el clasificador confunde con mayor frecuencia.\n",
    "\n",
    "Las filas de la matriz muestran el número de instancias reales de cada clase. Las columnas de la matriz muestran el número de instancias predichas por el clasificador en cada clase. Los elementos de la diagonal son los que se han predicho correctamente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uquEVMDPQieQ",
    "outputId": "b24b1794-a29e-47f1-8d31-06fd2e1ff767"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40,  2],\n",
       "       [ 2, 70]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_test_predicted =clf.predict(X_test)\n",
    "                            \n",
    "confusion_matrix(y_test, y_test_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vb52QHt5Qig6"
   },
   "source": [
    "También podemos dibujar la matriz de confusión de forma gráfica con la siguiente función auxiliar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PcGS8-vRQihr"
   },
   "outputs": [],
   "source": [
    "# Función extraída de\n",
    "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BuO2lNeFQijB",
    "outputId": "eb789ae2-6076-4efa-9d56-99de62f14bc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[0.95238095 0.04761905]\n",
      " [0.02777778 0.97222222]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Normalized confusion matrix'}, xlabel='Predicted label', ylabel='True label'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# El parámetro normalize permite mostrar los porcentajes en lugar del número de instancias\n",
    "plot_confusion_matrix(y_test, y_test_predicted, breast['target_names'], normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tty6XFClQile"
   },
   "source": [
    "## Validación cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VYB6dy0IQimB"
   },
   "source": [
    "La técnica de validación cruzada nos permite obtener métricas sobre el comportamiento de un clasificador mucho más representativas de su funcionamiento real. Se divide el conjunto de datos en K partes y se entrena el clasificador K veces usando cada vez una parte distinta como conjunto de prueba (y el resto como conjunto de entrenamiento). Las métricas sobre el funcionamiento del clasificador se obtienen calculando la media de las obtenidas en las K iteraciones.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation\n",
    "\n",
    "__Nota: no confundir la K de la validación cruzada con la K de los vecinos más cercanos, son variables distintas__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nz465pNsQimr",
    "outputId": "68cb24b6-e703-40b3-b9ff-cb11bc06c267"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00068831, 0.00047421, 0.00043607, 0.00040913, 0.00040865,\n",
       "        0.0005157 , 0.00040913, 0.00039983, 0.00040078, 0.00040293]),\n",
       " 'score_time': array([0.00147367, 0.00125289, 0.0012219 , 0.00119686, 0.00135136,\n",
       "        0.00125527, 0.00118208, 0.00114417, 0.00116992, 0.00124693]),\n",
       " 'test_score': array([0.96491228, 0.94736842, 0.94736842, 0.98245614, 1.        ,\n",
       "        1.        , 0.92982456, 0.98245614, 0.98245614, 0.96428571])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "import numpy as np\n",
    "\n",
    "# Creamos el clasificador k-NN\n",
    "clf = KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
    "\n",
    "# Validación cruzada dividiendo el conjunto de datos en 10 partes (folds)\n",
    "# cross_validate usa validación estratificada para problemas de clasificación binaria o multiclase\n",
    "scores = cross_validate(clf, breast['data_scaled'], breast['target'], scoring='accuracy', \n",
    "                        cv=10, return_train_score=False)\n",
    "\n",
    "# scores es un diccionario con datos sobre tiempos y exactitud (accuracy)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qIsH_Vm9Qiou",
    "outputId": "ad23fbc5-2f43-4f23-96d7-90197277062f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy mean: 0.9701127819548871\n",
      "Accuracy std: 0.022276264602112666\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy mean:', np.mean(scores['test_score']))\n",
    "print('Accuracy std:', np.std(scores['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MqBpvLWSQiqw"
   },
   "source": [
    "## Seleccionando el valor de k para k-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mJenKDFIQirU"
   },
   "source": [
    "Podemos seleccionar el valor óptimo de vecinos más cercanos usando validación cruzada con distintos valores de k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hMfvd0FPQiru",
    "outputId": "1635746b-6328-45d4-f875-e9997484cf25"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9542293233082708,\n",
       " 0.9542293233082708,\n",
       " 0.9701127819548871,\n",
       " 0.9736215538847117,\n",
       " 0.9666353383458647,\n",
       " 0.9683897243107771,\n",
       " 0.9666040100250626,\n",
       " 0.9718984962406015,\n",
       " 0.9666353383458647,\n",
       " 0.9701127819548871,\n",
       " 0.9718984962406015,\n",
       " 0.9718671679197994,\n",
       " 0.9701127819548871,\n",
       " 0.9736215538847117]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Medias y desviaciones típicas de accuracy para distintos valores de k\n",
    "accuracy_mean = []\n",
    "accuracy_std = []\n",
    "\n",
    "k_values = range(1,15)\n",
    "for k in k_values: \n",
    "    # Entrenar y validar\n",
    "    clf = KNeighborsClassifier(k, weights='distance')\n",
    "    scores = cross_validate(clf, breast['data_scaled'], breast['target'], scoring='accuracy', cv=10)\n",
    "    \n",
    "    accuracy_mean.append(np.mean(scores['test_score']))\n",
    "    accuracy_std.append(np.std(scores['test_score']))\n",
    "    \n",
    "accuracy_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e4b0vSYvQitc",
    "outputId": "c2bdd871-1d70-4b91-9ed0-39c013858251"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dibujamos la línea con la accuracy (exactitud) en el test\n",
    "plt.plot(k_values, accuracy_mean, color=\"g\", label=\"Accuracy\")\n",
    "\n",
    "# Dibujamos la banda de la desviación típica\n",
    "lower_limit = np.array(accuracy_mean) - np.array(accuracy_std)\n",
    "upper_limit = np.array(accuracy_mean) + np.array(accuracy_std)\n",
    "plt.fill_between(k_values, lower_limit, upper_limit, color=\"#DDDDDD\")\n",
    "\n",
    "# Creamos el gráfico\n",
    "plt.title(\"Curva de aprendizaje\")\n",
    "plt.xlabel(\"Parametro\"), plt.ylabel(\"Accuracy Score\"), plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CcBNHcjdQiuz"
   },
   "source": [
    "¿Qué valor de k seleccionarías a la vista de los resultados?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métricas detalladas por clase\n",
    "\n",
    "Cuando las clases están descompensadas, el valor de exactitud (accuracy) obtenido por el clasificador puede no ser demasiado representativo representativo de su funcionamiento. En estos casos conviene calcular los valores de precisión (precision), exahustividad (recall) y la medida F1 (F1 score) para cada una de las clases, además de los valores agregados.\n",
    "\n",
    "Empezamos calculando los valores agregados haciendo una media ponderada de los valores de cada clase según el número de instancias de cada clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00067687, 0.0004251 , 0.00046206, 0.00040197, 0.00048018,\n",
       "        0.00040293, 0.00043964, 0.00038886, 0.00043583, 0.00043225]),\n",
       " 'score_time': array([0.0042181 , 0.00347376, 0.00345969, 0.00354099, 0.00370193,\n",
       "        0.00335813, 0.00325704, 0.00333905, 0.00381804, 0.00356293]),\n",
       " 'test_precision_weighted': array([0.98321892, 0.96680891, 0.94743954, 0.9829303 , 1.        ,\n",
       "        1.        , 0.951417  , 0.98325359, 0.96491228, 0.96428571]),\n",
       " 'test_recall_weighted': array([0.98245614, 0.96491228, 0.94736842, 0.98245614, 1.        ,\n",
       "        1.        , 0.94736842, 0.98245614, 0.96491228, 0.96428571]),\n",
       " 'test_f1_weighted': array([0.98252394, 0.96456419, 0.94708706, 0.98236235, 1.        ,\n",
       "        1.        , 0.94639676, 0.98253659, 0.96491228, 0.96428571])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importamos las métricas que vamos a evaluar para cada una de las clases\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Escribimos las métricas que queremos evaluar\n",
    "# Precisión, Exhausitividad y F1 se calculan para cada clase\n",
    "# Existen diferentes formas de agregar el resultado de cada clase.  \n",
    "# Nosotors optamos por calcular el valor de cada clase, y hacer una media ponderada según\n",
    "# la proporción de instancias de cada clase en la muestra porque la muestra está desbalanceada\n",
    "scoring_metrics = ['precision_weighted', 'recall_weighted','f1_weighted']\n",
    "\n",
    "# Los mejores resultados se obtenían para k=4 sobre los datos re-escalados\n",
    "clf = KNeighborsClassifier(4, weights='distance')\n",
    "\n",
    "# Calculamos las métricas sobre los datos escalados utilizando validación cruzada\n",
    "# Por defecto usa \"estratificación\"\n",
    "scores = cross_validate(clf, breast['data_scaled'], breast['target'], scoring=scoring_metrics, \n",
    "                        cv=10, return_train_score=False)\n",
    "\n",
    "# scores te devuelve un diccionario con varios elementos, \n",
    "# entre ellos los resultados de las métricas elegidas en el test\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión ponderada media:  0.9744266262115232\n",
      "Exhaustividad ponderada media:  0.9736215538847117\n",
      "F1 ponderado media:  0.9734668894548844\n"
     ]
    }
   ],
   "source": [
    "print('Precisión ponderada media: ',np.mean(scores['test_precision_weighted']))\n",
    "print('Exhaustividad ponderada media: ',np.mean(scores['test_recall_weighted']))\n",
    "print('F1 ponderado media: ',np.mean(scores['test_f1_weighted']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a calcular la precisión, exahustividad y medida F1 de cada una de las clases por separado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.98      0.95      0.96       212\n",
      "      benign       0.97      0.99      0.98       357\n",
      "\n",
      "    accuracy                           0.97       569\n",
      "   macro avg       0.97      0.97      0.97       569\n",
      "weighted avg       0.97      0.97      0.97       569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Esta función entrena 10 clasificadores usando validación cruzada y devuelve una predicción\n",
    "# para cada punto usando el clasificador que no fue entrenado con ese punto\n",
    "clf = KNeighborsClassifier(4, weights='distance')\n",
    "predictions = cross_val_predict(clf, breast['data_scaled'], breast['target'], cv=10)\n",
    "\n",
    "# Informe por clases\n",
    "cr = classification_report(breast['target'], predictions, target_names=breast['target_names'])\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso podemos ver que el clasificador se comporta muy bien para las dos clases aunque un poco mejor para la \"benigna\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Podemos hacerlo mejor?\n",
    "\n",
    "Quizás, porque prácticamente no hemos preprocesado los datos. Es posible que no todas las variables del conjunto de datos aporten información útil para el problema que estamos tratando de resolver. O quizás sí porque este es un conjunto de datos de juguete que ha sido seleccionado para este problema en particular.\n",
    "\n",
    "En cualquier caso conviene recordar que kNN es muy sensible a variables redundantes o no relevantes porque afectan a la distancia entre puntos que usamos para clasificar. Podríamos tratar de buscar un mejor subconjunto de variables y volver a repetir todo el proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "05-k-NN y Validación cruzada.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
